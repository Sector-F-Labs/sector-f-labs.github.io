<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Sector F Labs</title>
  <link rel="icon" type="image/png" href="logo-nocircle.png">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Sector F Labs is a space for bold experimentation and beautifully simple tools. We break traditional molds to build systems that are powerful, privacy-respecting, and human-centered.">
  <meta property="og:title" content="Sector F Labs">
  <meta property="og:description" content="Sector F Labs is a space for bold experimentation and beautifully simple tools. We break traditional molds to build systems that are powerful, privacy-respecting, and human-centered.">
  <meta property="og:image" content="logo.png">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://sectorflabs.com/">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Sector F Labs">
  <meta name="twitter:description" content="Sector F Labs is a space for bold experimentation and beautifully simple tools.">
  <meta name="twitter:image" content="logo.png">
  <link rel="stylesheet" href="/style.css">
</head>
<body>
  <header>
    <a href="/index.html">
      <img src="/logo.png" alt="Sector F Logo">
      <h2>Sector F Labs</h2>
    </a>
  </header>

  <nav>
    <ul>
      <li><a href="/projects/md-chat">md-chat</a></li>
<li><a href="/projects/reservoir">Reservoir</a></li>
    </ul>
  </nav>

  <main>
    <h1>üöß Under Construction</h1>
<blockquote>
<p>Reservoir is in active development. It‚Äôs not ready for production use yet. Expect breaking changes.</p>
</blockquote>
<h1>Reservoir</h1>
<h2>What is Reservoir?</h2>
<p>Reservoir is your helpful memory for AI conversations. It sits between your app and the OpenAI Chat Completions API, making it easier to have rich, ongoing conversations with your favorite language models.</p>
<h3>Why does this matter?</h3>
<p>When you use the <a href="https://platform.openai.com/docs/guides/chat">OpenAI Chat Completions API</a>, you need to send the full conversation history with every request. For example:</p>
<div class="code-block"><pre><button class="copy-btn">Copy</button><code class="language-json">[
  {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What is 1 + 1?&quot;},
  {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;2&quot;},
  {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What is the answer times 3?&quot;}
]
</code></pre></div>
<p>If you only send the last question, the model won‚Äôt know what ‚Äúthe answer‚Äù refers to. You have to keep track of all previous messages and include them every time.</p>
<p><strong>This can get tricky as conversations grow!</strong></p>
<p>Reservoir acts as a smart proxy: it automatically stores your chat history and inserts the right context into each request. You just talk to the API as usual and Reservoir handles the memory, context, and even finds other relevant messages from your past conversations to help the model give better answers.</p>
<ul>
<li>No more manual history management</li>
<li>Automatic context enrichment</li>
<li>Your data stays private and local</li>
</ul>
<h3>Use Reservoir with Multiple Apps</h3>
<p>You can point multiple apps or clients to a single Reservoir instance. This means you can keep context and history across different tools on your computer‚Äîlike your terminal, a web app, or a chat client. If you want to keep conversations separate, you can use Reservoir‚Äôs partitioning feature to organize chats by app, project, or any context you choose.</p>
<h2>Why Use Reservoir?</h2>
<ul>
<li><strong>Own your AI history</strong>: All your conversations are stored locally, never in the cloud.</li>
<li><strong>Search and recall</strong>: Instantly find previous chats, ideas, or code snippets from your AI interactions.</li>
<li><strong>Enrich context</strong>: Automatically inject relevant history into new prompts for more coherent, personalized responses.</li>
<li><strong>Visualize conversations</strong>: See how your discussions branch and connect over time.</li>
<li><strong>Stay private</strong>: Your data never leaves your device.</li>
</ul>
<p><img src="./logo_256.png" alt="Screenshot" /></p>
<p>Reservoir lets you have conversations with multiple AI models and providers, all while keeping your data private and local. Every interaction is stored on your device, building a personal knowledge base that never leaves your network. A single thread of conversation can span multiple models without losing context, allowing you to seamlessly switch between different AI providers while maintaining the flow of your discussion.</p>
<h2>Table of Contents</h2>
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#conversation-threads-via-synapses">Conversation Threads via Synapses</a></li>
<li><a href="#documentation">Documentation</a></li>
<li><a href="#quick-start">Quick Start</a></li>
<li><a href="#license">License</a></li>
</ul>
<h2>Overview</h2>
<p>Reservoir intercepts your API calls, enriches them with relevant history, manages token limits, and then forwards them to the actual LLM service.</p>
<div class="code-block"><pre><button class="copy-btn">Copy</button><code class="language-mermaid">sequenceDiagram
    participant App
    participant Reservoir
    participant Neo4j
    participant LLM as OpenAI/Ollama

    App-&gt;&gt;Reservoir: Request (e.g. /v1/chat/completions/$USER/my-application)
    Reservoir-&gt;&gt;Reservoir: Check if last message exceeds token limit (Return error if true)
    Reservoir-&gt;&gt;Reservoir: Tag with Trace ID + Partition
    Reservoir-&gt;&gt;Neo4j: Store original request message(s)

    %% --- Context Enrichment Steps ---
    Reservoir-&gt;&gt;Neo4j: Query for similar &amp; recent messages
    Neo4j--&gt;&gt;Reservoir: Return relevant context messages
    Reservoir-&gt;&gt;Reservoir: Inject context messages into request payload
    %% --- End Enrichment Steps ---

    Reservoir-&gt;&gt;Reservoir: Check total token count &amp; truncate if needed (preserving system/last messages)

    Reservoir-&gt;&gt;LLM: Forward enriched &amp; potentially truncated request
    LLM-&gt;&gt;Reservoir: Return LLM response
    Reservoir-&gt;&gt;Neo4j: Store LLM response message
    Reservoir-&gt;&gt;App: Return LLM response
</code></pre></div>
<p>This sequence diagram provides a high-level overview of how Reservoir processes requests and responses.</p>
<h2>Conversation Threads via Synapses</h2>
<p>Reservoir uses synapse relationships to create ‚Äúthreads‚Äù of semantically related messages within the conversation graph. As messages are added, synapses link them sequentially, forming a continuous flow. When the similarity between messages drops below a threshold, the thread is split, marking a topic change. This results in distinct conversation threads, making it easy to visualize and retrieve related exchanges.</p>
<p>You can see an example of this structure in the following graph visualization:</p>
<p><img src="./conversation_graph_view.png" alt="Conversation Graph View" /></p>
<h2>Documentation</h2>
<p>Reservoir's documentation is organized into the following sections:</p>
<ul>
<li><a href="./docs/architecture.md">Architecture</a>: System and component overview.</li>
<li><a href="./docs/api.md">API</a>: API endpoints, usage, and examples.</li>
<li><a href="./docs/data_model.md">Data Model</a>: How data is stored in Neo4j, including the schema.</li>
<li><a href="./docs/dev.md">Development</a>: Setting up the development environment, running locally, and contributing.</li>
<li><a href="./docs/features.md">Features</a>: Key features and future roadmap.</li>
<li><a href="./docs/deployment.md">Deployment</a>: Steps to deploy Reservoir locally or in production.</li>
<li><a href="./docs/faq.md">FAQ</a>: Troubleshooting, common questions, and tips.</li>
</ul>
<h2>Quick Start</h2>
<p>Reservoir provides an OpenAI-compatible API endpoint. You can use your system username as the partition and your application name as the instance for best results.</p>
<h3>Example Usage</h3>
<ul>
<li><strong>Instead of</strong>:
https://api.openai.com/v1/chat/completions</li>
<li><strong>Use</strong>:
http://localhost:3017/v1/partition/$USER/instance/my-application/chat/completions</li>
</ul>
<p>Here, <code>$USER</code> is the system username, and <code>my-application</code> is the instance. Context enrichment and history retrieval are scoped to the specific <code>partition</code>/<code>instance</code> combination.</p>
<h4>Curl Example</h4>
<div class="code-block"><pre><button class="copy-btn">Copy</button><code class="language-bash">curl http://localhost:3017/v1/partition/$USER/instance/my-application/chat/completions \
    -H &quot;Content-Type: application/json&quot; \
    -H &quot;Authorization: Bearer $OPENAI_API_KEY&quot; \
    -d '{
        &quot;model&quot;: &quot;gpt-4&quot;,
        &quot;messages&quot;: [
            {
                &quot;role&quot;: &quot;user&quot;,
                &quot;content&quot;: &quot;Write a one-sentence bedtime story about a brave little toaster.&quot;
            }
        ]
    }'
</code></pre></div>
<h4>Python Example (using <code>openai</code> library)</h4>
<div class="code-block"><pre><button class="copy-btn">Copy</button><code class="language-python">import os
from openai import OpenAI

INSTANCE = &quot;my-application&quot;
PARTITION = os.getenv(&quot;USER&quot;)
RESERVOIR_PORT = os.getenv('RESERVOIR_PORT', '3017')
RESERVOIR_BASE_URL = f&quot;http://localhost:{RESERVOIR_PORT}/v1/partition/{PARTITION}/instance/{INSTANCE}&quot;

client = OpenAI(
    base_url=RESERVOIR_BASE_URL,
    api_key=os.environ.get(&quot;OPENAI_API_KEY&quot;)
)

completion = client.chat.completions.create(
    model=&quot;gpt-4&quot;,
    messages=[
        {
            &quot;role&quot;: &quot;user&quot;,
            &quot;content&quot;: &quot;Write a one-sentence bedtime story about a curious robot.&quot;
        }
    ]
)
print(completion.choices[0].message.content)
</code></pre></div>
<h2>License</h2>
<p>This project is licensed under the Apache License 2.0 - see the <a href="LICENSE">LICENSE</a> file for details.</p>

  </main>

  <footer>
    <hr>
    <p>&copy; 2025 Sector F Labs. All rights reserved.</p>
  </footer>

  <script>
    document.addEventListener('DOMContentLoaded', function() {
      document.querySelectorAll('.copy-btn').forEach(function(btn) {
        btn.addEventListener('click', function(e) {
          e.preventDefault();
          var pre = btn.closest('pre');
          if (!pre) return;
          // Get all code text inside the pre
          var code = pre.querySelector('code');
          var text = code ? code.innerText : pre.innerText;
          navigator.clipboard.writeText(text);
          btn.textContent = 'Copied!';
          setTimeout(function() { btn.textContent = 'Copy'; }, 1200);
        });
      });
    });
  </script>
</body>
</html>
